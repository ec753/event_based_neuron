{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "547d4350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from neuron import h\n",
    "from neuron.units import mV, ms\n",
    "h.load_file(\"stdrun.hoc\")\n",
    "h.load_file(\"stdlib.hoc\")\n",
    "h.load_file(\"import3d.hoc\")\n",
    "h.load_file(\"stdrun.hoc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcca0f0a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f834d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/state_reconstruct_morpho/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "565c8eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poisson_Times:\n",
    "    def __init__(self, _id, tau, interval, weight, rev_potential, event_times=None, max_time=1000000, number=99999999,\n",
    "                 delay=0, start=0):\n",
    "        '''\n",
    "        :param _id:\n",
    "        :param event_times: instead of auto generating, provide a list of event_times\n",
    "        :param max_time: maximum time (simulation duration)\n",
    "        :param number: maximum number of stimuli (typically inconsequential if max_time is reasonable)\n",
    "        '''\n",
    "\n",
    "        self._id = _id\n",
    "        self.rev_potential = rev_potential\n",
    "        self.max_time = max_time\n",
    "        self.interval = interval\n",
    "        self.weight = weight\n",
    "        self.delay = delay\n",
    "        self.tau = tau\n",
    "        self.start = start\n",
    "        self.number = number\n",
    "        self.event_times = []\n",
    "\n",
    "        if event_times:\n",
    "            # load event times\n",
    "            self.event_times = event_times\n",
    "        else:\n",
    "            # generate event times\n",
    "            event_time = 0\n",
    "            for i in range(number):\n",
    "                event_time += np.random.exponential(self.interval)\n",
    "                if event_time < max_time:\n",
    "                    self.event_times.append(event_time)\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    def write2file(self, path):\n",
    "        stimuli_data = {\n",
    "            '_id': self._id,\n",
    "            'rev_potential': self.rev_potential,\n",
    "            'max_time': self.max_time,\n",
    "            'interval': self.interval,\n",
    "            'weight': self.weight,\n",
    "            'delay': self.delay,\n",
    "            'tau': self.tau,\n",
    "            'start': self.start,\n",
    "            'number': self.number,\n",
    "            'event_times': self.event_times\n",
    "        }\n",
    "\n",
    "        with open(path, 'w') as fout:\n",
    "            fout.write(json.dumps(stimuli_data))\n",
    "            \n",
    "class Pyramidal:\n",
    "    def __init__(self, record_spiking_histories=False):\n",
    "        self.load_morphology()\n",
    "        # do discretization, ion channels, etc\n",
    "        for sec in self.all:\n",
    "            sec.nseg = int(1 + 2 * (sec.L // 40))\n",
    "        h.hh.insert(self.axon)\n",
    "        h.hh.insert(self.soma)\n",
    "        h.pas.insert(self.dend)  # passive leak\n",
    "        h.pas.insert(self.apic)  # passive leak\n",
    "        self.all_input_segments = []\n",
    "        for morph in [self.apic, self.dend]:\n",
    "            for part in morph:\n",
    "                # self.all_input_segments.append(part)\n",
    "                self.all_input_segments.extend([seg for seg in part])\n",
    "        self._clear_cell(record_spiking_histories)\n",
    "\n",
    "    def _clear_cell(self, record_spiking_histories):\n",
    "        # storing input mechanisms\n",
    "        self.syns = []\n",
    "        self.net_stims = []\n",
    "        self.netcons = []\n",
    "        self.stims = []\n",
    "        # recording\n",
    "        self.v_apic = h.Vector().record(self.apic[100](0.5)._ref_v)\n",
    "        self.v_soma = h.Vector().record(self.soma[0](0.5)._ref_v)\n",
    "        self.v_axon = h.Vector().record(self.axon[0](0.5)._ref_v)\n",
    "        self._t = h.Vector().record(h._ref_t)\n",
    "\n",
    "        self.v = [h.Vector().record(seg._ref_v) for sec in self.all for seg in sec]\n",
    "        self.hh_secs = [sec for sec in self.all if 'hh' in sec.psection()['density_mechs']]\n",
    "\n",
    "        '''\n",
    "        self.m = [h.Vector().record(seg.hh._ref_m) for sec in hh_secs for seg in sec]\n",
    "        self.h = [h.Vector().record(seg.hh._ref_h) for sec in hh_secs for seg in sec]\n",
    "        self.n = [h.Vector().record(seg.hh._ref_n) for sec in hh_secs for seg in sec]\n",
    "        '''\n",
    "\n",
    "        self.spike_detector = h.NetCon(self.axon[0](0.5)._ref_v, None, sec=self.axon[0])\n",
    "        self.spike_times = h.Vector()\n",
    "        self.spike_detector.record(self.spike_times)\n",
    "\n",
    "        if record_spiking_histories:\n",
    "            self.spiking_histories = []\n",
    "            self.spike_detector2 = h.NetCon(self.axon[0](0.5)._ref_v, None, sec=self.axon[0])\n",
    "            self.spike_detector2.record(self.save)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"pyr\"\n",
    "\n",
    "    def get_state(self):\n",
    "        return {\n",
    "            \"v\": [seg.v for sec in self.all for seg in sec],\n",
    "            \"m\": [seg.hh.m for sec in self.hh_secs for seg in sec],\n",
    "            \"h\": [seg.hh.h for sec in self.hh_secs for seg in sec],\n",
    "            \"n\": [seg.hh.n for sec in self.hh_secs for seg in sec]}\n",
    "\n",
    "    def save(self):\n",
    "        self.spiking_histories.append(self.get_state())\n",
    "\n",
    "    def set_initialize_state(self, state):\n",
    "        self._initial_state = state\n",
    "        self.fih = h.FInitializeHandler(self._do_initial)\n",
    "\n",
    "    def _do_initial(self):\n",
    "        # state: state dict from self.get_state()\n",
    "        all_segs = [seg for sec in self.all for seg in sec]\n",
    "        hh_segs = [seg for sec in self.hh_secs for seg in sec]\n",
    "        for seg, v in zip(all_segs, self._initial_state[\"v\"]):\n",
    "            seg.v = v\n",
    "        for seg, m, h, n in zip(hh_segs, self._initial_state[\"m\"], self._initial_state[\"h\"], self._initial_state[\"n\"]):\n",
    "            seg.hh.m = m\n",
    "            seg.hh.n = n\n",
    "            seg.hh.h = h\n",
    "\n",
    "    def load_morphology(self):\n",
    "        cell = h.Import3d_SWC_read()\n",
    "        cell.input(\"./resources/neuron_nmo/amaral/CNG version/c91662.CNG.swc\")\n",
    "        i3d = h.Import3d_GUI(cell, False)\n",
    "        i3d.instantiate(self)\n",
    "\n",
    "    def connect_input(self, stimuli, seg):\n",
    "        '''\n",
    "        :param stimuli: Poisson_Times class object\n",
    "        :param seg: NEURON simulation segment\n",
    "        :return:\n",
    "        '''\n",
    "        syn = h.ExpSyn(seg)\n",
    "        syn.tau = stimuli.tau\n",
    "        syn.e = stimuli.rev_potential\n",
    "\n",
    "        vec_stim_times = h.Vector(stimuli.event_times)\n",
    "        vec_stim = h.VecStim()\n",
    "        vec_stim.play(vec_stim_times)\n",
    "\n",
    "        nc = h.NetCon(vec_stim, syn)\n",
    "        nc.weight[0] = 1  # stimuli.weight\n",
    "        nc.delay = stimuli.delay\n",
    "\n",
    "        self.syns.append(syn)\n",
    "        self.netcons.append(nc)\n",
    "\n",
    "        netstims = [h.NetStim() for stim_time in stimuli.event_times]\n",
    "        for netstim, event_time in zip(netstims, stimuli.event_times):\n",
    "            netstim.number = 1\n",
    "            netstim.start = event_time\n",
    "            netcon = h.NetCon(netstim, syn)\n",
    "            netcon.weight[0] = stimuli.weight\n",
    "            netcon.delay = 0 * ms\n",
    "\n",
    "            self.netcons.append(netcon)\n",
    "        self.stims.extend(netstims)\n",
    "\n",
    "    def load_stimuli_from_file(self, stimuli_file):\n",
    "        with open(stimuli_file, 'r') as fin:\n",
    "            stimuli_json = json.load(fin)\n",
    "        for seg_ind in stimuli_json:\n",
    "            stimuli = Poisson_Times(\n",
    "                stimuli_json[seg_ind]['stim_type'],\n",
    "                stimuli_json[seg_ind]['tau'],\n",
    "                stimuli_json[seg_ind]['interval'],\n",
    "                stimuli_json[seg_ind]['weight'],\n",
    "                stimuli_json[seg_ind]['rev_potential'],\n",
    "                event_times=stimuli_json[seg_ind]['event_times']\n",
    "            )\n",
    "            self.connect_input(stimuli, self.all_input_segments[int(seg_ind)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "214c6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_duration = 100\n",
    "initial_simulation_duration = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0235862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "\n",
    "# load spikes\n",
    "with open(f'{data_dir}original_simulation_data/spikes_{ind}.txt', 'r') as fin:\n",
    "    spikes = [float(x.strip()) for x in fin.readlines()]\n",
    "\n",
    "# set up reconstruction cell\n",
    "reconstruction_cell = Pyramidal()\n",
    "reconstruction_cell.load_morphology()\n",
    "\n",
    "# load stimuli\n",
    "stimuli_files = os.listdir(f'{data_dir}original_simulation_data/stimuli_{ind}')\n",
    "for stimuli_file in stimuli_files:    \n",
    "    with open(f'{data_dir}original_simulation_data/stimuli_{ind}/{stimuli_file}', 'r') as f:\n",
    "        stimuli_data = json.load(f)\n",
    "        seg_ind = int(stimuli_file.split('.')[1])\n",
    "        stimuli = Poisson_Times(\n",
    "            _id = stimuli_data['_id'],\n",
    "            tau = stimuli_data['tau'], \n",
    "            interval = stimuli_data['interval'], \n",
    "            weight = stimuli_data['weight'], \n",
    "            rev_potential = stimuli_data['rev_potential'], \n",
    "            event_times = stimuli_data['event_times']\n",
    "        )\n",
    "    reconstruction_cell.connect_input(stimuli, reconstruction_cell.all_input_segments[seg_ind])\n",
    "state_vars = np.load(f'{data_dir}original_simulation_data/state_vars_{ind}.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dac896b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[66.02500000010644,\n",
       " 83.20000000011035,\n",
       " 104.5000000001152,\n",
       " 153.10000000009768,\n",
       " 222.27500000003477,\n",
       " 238.6250000000199,\n",
       " 280.6249999999817,\n",
       " 299.04999999996494,\n",
       " 316.9249999999487,\n",
       " 349.9999999999186,\n",
       " 383.5499999998881,\n",
       " 434.14999999984207,\n",
       " 449.8249999998278,\n",
       " 497.0999999997848,\n",
       " 515.5499999997842,\n",
       " 538.9249999998692,\n",
       " 553.3499999999217,\n",
       " 586.8000000000434,\n",
       " 607.6750000001193,\n",
       " 646.5250000002607,\n",
       " 703.2750000004671,\n",
       " 740.2250000006015,\n",
       " 763.2000000006851,\n",
       " 803.5000000008317,\n",
       " 856.8000000010256,\n",
       " 903.7750000011965,\n",
       " 956.6000000013887,\n",
       " 995.6500000015308,\n",
       " 1014.0750000015978,\n",
       " 1029.8750000016553,\n",
       " 1077.375000001828,\n",
       " 1100.175000001911,\n",
       " 1164.5750000021453,\n",
       " 1204.4750000022905,\n",
       " 1225.800000002368,\n",
       " 1278.1500000025585,\n",
       " 1313.0250000026854,\n",
       " 1333.3750000027594,\n",
       " 1366.8500000028812,\n",
       " 1390.4750000029671,\n",
       " 1421.4500000030798,\n",
       " 1475.625000003277,\n",
       " 1495.0000000033474,\n",
       " 1590.6750000036955,\n",
       " 1620.0750000038024,\n",
       " 1652.100000003919,\n",
       " 1714.4750000041458,\n",
       " 1727.5750000041935,\n",
       " 1745.025000004257,\n",
       " 1771.975000004355,\n",
       " 1800.9000000044603,\n",
       " 1821.6500000045357,\n",
       " 1886.05000000477,\n",
       " 1906.3250000048438,\n",
       " 1949.9500000050025,\n",
       " 1967.8000000050674,\n",
       " 2016.3750000052441,\n",
       " 2034.47500000531,\n",
       " 2060.9750000051704,\n",
       " 2081.0500000048783,\n",
       " 2147.7750000039073,\n",
       " 2182.9500000033954,\n",
       " 2201.3000000031284,\n",
       " 2218.300000002881,\n",
       " 2240.025000002565,\n",
       " 2272.450000002093,\n",
       " 2288.175000001864,\n",
       " 2335.275000001179,\n",
       " 2374.900000000602,\n",
       " 2410.0500000000907,\n",
       " 2509.0249999986504,\n",
       " 2526.6749999983936,\n",
       " 2549.399999998063,\n",
       " 2601.4999999973047,\n",
       " 2699.549999995878,\n",
       " 2736.3249999953428,\n",
       " 2784.274999994645,\n",
       " 2841.5499999938115,\n",
       " 2856.899999993588,\n",
       " 2879.4999999932593,\n",
       " 2920.074999992669,\n",
       " 2941.8749999923516,\n",
       " 2959.574999992094,\n",
       " 2974.7999999918725,\n",
       " 3067.7749999905195,\n",
       " 3110.699999989895,\n",
       " 3158.299999989202,\n",
       " 3173.2499999889847,\n",
       " 3208.674999988469,\n",
       " 3242.1999999879813,\n",
       " 3272.5499999875396,\n",
       " 3326.2249999867586,\n",
       " 3358.9249999862827,\n",
       " 3408.249999985565,\n",
       " 3451.474999984936,\n",
       " 3468.5999999846867,\n",
       " 3483.9499999844634,\n",
       " 3513.4999999840334,\n",
       " 3552.499999983466,\n",
       " 3614.7999999825593,\n",
       " 3646.849999982093,\n",
       " 3709.6999999811783,\n",
       " 3734.7749999808134,\n",
       " 3784.9999999800825,\n",
       " 3807.0749999797613,\n",
       " 3885.024999978627,\n",
       " 3909.0249999782777,\n",
       " 3969.5249999773973,\n",
       " 3991.0749999770837,\n",
       " 4026.4249999765693,\n",
       " 4073.449999975885,\n",
       " 4102.7249999754595,\n",
       " 4151.299999974753,\n",
       " 4166.874999974526,\n",
       " 4205.224999973968,\n",
       " 4249.874999973318,\n",
       " 4309.824999972446,\n",
       " 4355.999999971774,\n",
       " 4394.149999971219,\n",
       " 4412.424999970953,\n",
       " 4453.999999970348,\n",
       " 4491.999999969795,\n",
       " 4528.699999969261,\n",
       " 4562.974999968762,\n",
       " 4626.849999967832,\n",
       " 4673.874999967148,\n",
       " 4756.974999965939,\n",
       " 4780.874999965591,\n",
       " 4800.124999965311,\n",
       " 4817.099999965064,\n",
       " 4920.549999963559,\n",
       " 4945.549999963195]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spikes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
